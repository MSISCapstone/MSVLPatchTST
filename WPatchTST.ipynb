{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBbgpP9F+9htuwTz8h4Y4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSISCapstone/CSPatchTST/blob/mouryavs/WPatchTST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfcNGxMZxuld",
        "outputId": "05339c59-5558-4c9f-e889-4075f70239bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSPatchTST'...\n",
            "remote: Enumerating objects: 667, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 667 (delta 58), reused 52 (delta 38), pack-reused 578 (from 1)\u001b[K\n",
            "Receiving objects: 100% (667/667), 42.11 MiB | 26.92 MiB/s, done.\n",
            "Resolving deltas: 100% (336/336), done.\n",
            "Filtering content: 100% (2/2), 221.27 MiB | 45.14 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "! git clone -b mouryavs https://github.com/MSISCapstone/CSPatchTST.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CSPatchTST/WPatchTST\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1k6cHMVySYS",
        "outputId": "335b27d7-f6e9-4462-94de-4bdf61e2620e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSPatchTST/WPatchTST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyzvEnKGyWkY",
        "outputId": "97f63f57-f839-425d-a5a1-b0ec81cd1604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "environment.yml  requirements.txt  WPatchTST_Environment.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkF2V3myaTQ",
        "outputId": "7fc43e65-8c76-4101-dbe8-3815d9951566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.19.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (2.9.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiaz6X2KzqR_",
        "outputId": "9916af43-08d0-4ca2-e698-75243f34a5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CSPatchTST\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1bA9uMSDgYu",
        "outputId": "73822b79-aaec-4e39-8bea-e8ed4523604c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSPatchTST\n",
            "datasets  LICENSE    PatchTST_self_supervised  pic\t  WPatchTST\n",
            "docs\t  notebooks  PatchTST_supervised       README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -R \"patch_len\" -n . | head -n 25\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn76r1OcDqRu",
        "outputId": "2f8984c5-6c4f-44fc-e706-da313f440f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./PatchTST_supervised/scripts/PatchTST/etth2.sh:38:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/electricity.sh:38:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/ettm1.sh:38:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh:23:patch_lengths=\"6,12,24\"      # Three temporal scales\n",
            "./PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh:43:      --patch_lengths $patch_lengths \\\n",
            "./PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh:53:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/etth1.sh:38:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/ettm2.sh:38:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/univariate/etth2.sh:43:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/univariate/ettm1.sh:43:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/univariate/etth1.sh:43:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/univariate/ettm2.sh:43:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/weather_multiscale.sh:22:patch_lengths=\"6,12,24\"      # Three scales for weather (hourly data)\n",
            "./PatchTST_supervised/scripts/PatchTST/weather_multiscale.sh:41:      --patch_lengths $patch_lengths \\\n",
            "./PatchTST_supervised/scripts/PatchTST/weather_multiscale.sh:51:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/illness.sh:38:      --patch_len 24\\\n",
            "./PatchTST_supervised/scripts/PatchTST/traffic.sh:38:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/PatchTST/weather_crosschannel.sh:53:      --patch_len 16 \\\n",
            "./PatchTST_supervised/scripts/PatchTST/weather.sh:38:      --patch_len 16\\\n",
            "./PatchTST_supervised/scripts/test_all_enhancements.sh:65:  --patch_len 16 \\\n",
            "./PatchTST_supervised/scripts/test_all_enhancements.sh:103:  --patch_len 16 \\\n",
            "./PatchTST_supervised/scripts/test_all_enhancements.sh:134:  --patch_lengths \"6,12,24\" \\\n",
            "./PatchTST_supervised/scripts/test_all_enhancements.sh:144:  --patch_len 16 \\\n",
            "./PatchTST_supervised/scripts/test_all_enhancements.sh:175:  --patch_lengths \"6,12,24\" \\\n",
            "./PatchTST_supervised/scripts/test_all_enhancements.sh:185:  --patch_len 16 \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,120p' PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvm6-_jMEGwP",
        "outputId": "b50213a0-ef79-45cf-ee1a-d879405b8bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "\n",
            "# Multi-Scale + Cross-Channel PatchTST for Weather Forecasting\n",
            "# Combines both enhancements for maximum performance:\n",
            "#   - Multi-scale: Captures temporal patterns at 6hr, 12hr, 24hr scales\n",
            "#   - Cross-channel: Enables interaction between weather variables\n",
            "\n",
            "model_name=PatchTST\n",
            "random_seed=2021\n",
            "\n",
            "root_path_name=./dataset/\n",
            "data_path_name=weather.csv\n",
            "model_id_name=weather\n",
            "data_name=custom\n",
            "\n",
            "seq_len=336\n",
            "\n",
            "# Enable BOTH enhancements\n",
            "multi_scale=1\n",
            "channel_independent=0        # 0 = cross-channel (variables interact)\n",
            "\n",
            "# Multi-scale configuration\n",
            "patch_lengths=\"6,12,24\"      # Three temporal scales\n",
            "patch_strides=\"3,6,12\"       # 50% overlap for each\n",
            "patch_weights=\"0.2,0.5,0.3\"  # Balanced fusion\n",
            "\n",
            "for pred_len in 96 192 336 720\n",
            "do\n",
            "    python -u run_longExp.py \\\n",
            "      --random_seed $random_seed \\\n",
            "      --is_training 1 \\\n",
            "      --root_path $root_path_name \\\n",
            "      --data_path $data_path_name \\\n",
            "      --model_id $model_id_name'_multiCross_'$seq_len'_'$pred_len \\\n",
            "      --model $model_name \\\n",
            "      --data $data_name \\\n",
            "      --features M \\\n",
            "      --seq_len $seq_len \\\n",
            "      --pred_len $pred_len \\\n",
            "      --enc_in 21 \\\n",
            "      --channel_independent $channel_independent \\\n",
            "      --multi_scale $multi_scale \\\n",
            "      --patch_lengths $patch_lengths \\\n",
            "      --patch_strides $patch_strides \\\n",
            "      --patch_weights $patch_weights \\\n",
            "      --e_layers 3 \\\n",
            "      --n_heads 16 \\\n",
            "      --d_model 128 \\\n",
            "      --d_ff 256 \\\n",
            "      --dropout 0.2\\\n",
            "      --fc_dropout 0.2\\\n",
            "      --head_dropout 0\\\n",
            "      --patch_len 16\\\n",
            "      --stride 8\\\n",
            "      --des 'MultiScale_CrossChannel_Exp' \\\n",
            "      --train_epochs 100\\\n",
            "      --patience 20\\\n",
            "      --itr 1 --batch_size 128 --learning_rate 0.0001 >logs/LongForecasting/$model_name'_MultiCross_'$model_id_name'_'$seq_len'_'$pred_len.log \n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh \\\n",
        "    PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh.bak\n"
      ],
      "metadata": {
        "id": "IlcckBfVEvVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -R \"python -u\" -n PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8F7P1jeFn__",
        "outputId": "2e888ef4-bece-4c06-a73e-aaa89ca861d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29:    python -u run_longExp.py \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -R \"argparse\" -n PatchTST_supervised | head -n 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1PVGyyaF0bd",
        "outputId": "04e31974-5d77-461e-c8c5-15dbeb908eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PatchTST_supervised/Formers/Pyraformer/single_step_main.py:1:import argparse\r\n",
            "PatchTST_supervised/Formers/Pyraformer/single_step_main.py:241:    parser = argparse.ArgumentParser()\r\n",
            "PatchTST_supervised/Formers/Pyraformer/long_range_main.py:1:import argparse\n",
            "PatchTST_supervised/Formers/Pyraformer/long_range_main.py:311:    parser = argparse.ArgumentParser()\n",
            "PatchTST_supervised/Formers/Pyraformer/pyraformer/graph_attention.py:12:import argparse\n",
            "PatchTST_supervised/Formers/Pyraformer/pyraformer/graph_attention.py:428:    parser = argparse.ArgumentParser(description='Needed for graph self attention.')\n",
            "PatchTST_supervised/Formers/FEDformer/run.py:1:import argparse\n",
            "PatchTST_supervised/Formers/FEDformer/run.py:13:parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
            "PatchTST_supervised/run_longExp.py:1:import argparse\n",
            "PatchTST_supervised/run_longExp.py:9:    parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' PatchTST_supervised/run_longExp.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygWPjFZaF6L9",
        "outputId": "b95b6991-ecf1-4ed6-b102-757357549600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import argparse\n",
            "import os\n",
            "import torch\n",
            "from exp.exp_main import Exp_Main\n",
            "import random\n",
            "import numpy as np\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
            "\n",
            "    # random seed\n",
            "    parser.add_argument('--random_seed', type=int, default=2021, help='random seed')\n",
            "\n",
            "    # basic config\n",
            "    parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
            "    parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
            "    parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
            "                        help='model name, options: [Autoformer, Informer, Transformer]')\n",
            "\n",
            "    # data loader\n",
            "    parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
            "    parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
            "    parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
            "    parser.add_argument('--features', type=str, default='M',\n",
            "                        help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
            "    parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
            "    parser.add_argument('--freq', type=str, default='h',\n",
            "                        help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
            "    parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
            "\n",
            "    # forecasting task\n",
            "    parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
            "    parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
            "    parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\n",
            "\n",
            "\n",
            "    # DLinear\n",
            "    #parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
            "\n",
            "    # PatchTST\n",
            "    parser.add_argument('--fc_dropout', type=float, default=0.05, help='fully connected dropout')\n",
            "    parser.add_argument('--head_dropout', type=float, default=0.0, help='head dropout')\n",
            "    parser.add_argument('--patch_len', type=int, default=16, help='patch length')\n",
            "    parser.add_argument('--stride', type=int, default=8, help='stride')\n",
            "    parser.add_argument('--padding_patch', default='end', help='None: None; end: padding on the end')\n",
            "    parser.add_argument('--revin', type=int, default=1, help='RevIN; True 1 False 0')\n",
            "    parser.add_argument('--affine', type=int, default=0, help='RevIN-affine; True 1 False 0')\n",
            "    parser.add_argument('--subtract_last', type=int, default=0, help='0: subtract mean; 1: subtract last')\n",
            "    parser.add_argument('--decomposition', type=int, default=0, help='decomposition; True 1 False 0')\n",
            "    parser.add_argument('--kernel_size', type=int, default=25, help='decomposition-kernel')\n",
            "    parser.add_argument('--individual', type=int, default=0, help='individual head; True 1 False 0')\n",
            "    parser.add_argument('--channel_independent', type=int, default=1, help='channel independence; 0: cross-channel (variables interact), 1: channel-independent (variables separate); default 1')\n",
            "    \n",
            "    # Multi-scale patching (variable-length patches)\n",
            "    parser.add_argument('--multi_scale', type=int, default=0, help='enable multi-scale patching; 0: disabled (use single patch_len), 1: enabled (use multiple patch lengths)')\n",
            "    parser.add_argument('--patch_lengths', type=str, default='16', help='comma-separated patch lengths for multi-scale (e.g., \"6,12,24\" for weather); ignored if multi_scale=0')\n",
            "    parser.add_argument('--patch_strides', type=str, default='8', help='comma-separated strides for multi-scale (e.g., \"3,6,12\"); ignored if multi_scale=0')\n",
            "    parser.add_argument('--patch_weights', type=str, default='1.0', help='comma-separated weights for multi-scale fusion (e.g., \"0.2,0.5,0.3\"); auto-normalized; ignored if multi_scale=0')\n",
            "\n",
            "    # Formers \n",
            "    parser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
            "    parser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
            "    parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
            "    parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
            "    parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
            "    parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
            "    parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
            "    parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
            "    parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
            "    parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
            "    parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
            "    parser.add_argument('--distil', action='store_false',\n",
            "                        help='whether to use distilling in encoder, using this argument means not using distilling',\n",
            "                        default=True)\n",
            "    parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
            "    parser.add_argument('--embed', type=str, default='timeF',\n",
            "                        help='time features encoding, options:[timeF, fixed, learned]')\n",
            "    parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
            "    parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
            "    parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
            "\n",
            "    # optimization\n",
            "    parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
            "    parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
            "    parser.add_argument('--train_epochs', type=int, default=100, help='train epochs')\n",
            "    parser.add_argument('--batch_size', type=int, default=128, help='batch size of train input data')\n",
            "    parser.add_argument('--patience', type=int, default=100, help='early stopping patience')\n",
            "    parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
            "    parser.add_argument('--des', type=str, default='test', help='exp description')\n",
            "    parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
            "    parser.add_argument('--lradj', type=str, default='type3', help='adjust learning rate')\n",
            "    parser.add_argument('--pct_start', type=float, default=0.3, help='pct_start')\n",
            "    parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
            "\n",
            "    # GPU\n",
            "    parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
            "    parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
            "    parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
            "    parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
            "    parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n",
            "\n",
            "    args = parser.parse_args()\n",
            "    \n",
            "    # Parse multi-scale parameters if enabled\n",
            "    if args.multi_scale:\n",
            "        args.patch_lengths = [int(x.strip()) for x in args.patch_lengths.split(',')]\n",
            "        args.patch_strides = [int(x.strip()) for x in args.patch_strides.split(',')]\n",
            "        args.patch_weights = [float(x.strip()) for x in args.patch_weights.split(',')]\n",
            "        \n",
            "        # Validation\n",
            "        assert len(args.patch_lengths) == len(args.patch_strides), \\\n",
            "            f\"Number of patch lengths ({len(args.patch_lengths)}) must match number of strides ({len(args.patch_strides)})\"\n",
            "        assert len(args.patch_lengths) == len(args.patch_weights), \\\n",
            "            f\"Number of patch lengths ({len(args.patch_lengths)}) must match number of weights ({len(args.patch_weights)})\"\n",
            "        assert all(pl > 0 for pl in args.patch_lengths), \"All patch lengths must be positive\"\n",
            "        assert all(ps > 0 for ps in args.patch_strides), \"All strides must be positive\"\n",
            "        \n",
            "        # Normalize weights\n",
            "        weight_sum = sum(args.patch_weights)\n",
            "        args.patch_weights = [w / weight_sum for w in args.patch_weights]\n",
            "        \n",
            "        print(f\"Multi-scale patching enabled:\")\n",
            "        print(f\"  Patch lengths: {args.patch_lengths}\")\n",
            "        print(f\"  Strides: {args.patch_strides}\")\n",
            "        print(f\"  Normalized weights: {[f'{w:.3f}' for w in args.patch_weights]}\")\n",
            "\n",
            "    # random seed\n",
            "    fix_seed = args.random_seed\n",
            "    random.seed(fix_seed)\n",
            "    torch.manual_seed(fix_seed)\n",
            "    np.random.seed(fix_seed)\n",
            "\n",
            "\n",
            "    args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
            "\n",
            "    if args.use_gpu and args.use_multi_gpu:\n",
            "        args.dvices = args.devices.replace(' ', '')\n",
            "        device_ids = args.devices.split(',')\n",
            "        args.device_ids = [int(id_) for id_ in device_ids]\n",
            "        args.gpu = args.device_ids[0]\n",
            "\n",
            "    print('Args in experiment:')\n",
            "    print(args)\n",
            "\n",
            "    Exp = Exp_Main\n",
            "\n",
            "    if args.is_training:\n",
            "        for ii in range(args.itr):\n",
            "            # setting record of experiments\n",
            "            setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
            "                args.model_id,\n",
            "                args.model,\n",
            "                args.data,\n",
            "                args.features,\n",
            "                args.seq_len,\n",
            "                args.label_len,\n",
            "                args.pred_len,\n",
            "                args.d_model,\n",
            "                args.n_heads,\n",
            "                args.e_layers,\n",
            "                args.d_layers,\n",
            "                args.d_ff,\n",
            "                args.factor,\n",
            "                args.embed,\n",
            "                args.distil,\n",
            "                args.des,ii)\n",
            "\n",
            "            exp = Exp(args)  # set experiments\n",
            "            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
            "            exp.train(setting)\n",
            "\n",
            "            print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
            "            exp.test(setting)\n",
            "\n",
            "            if args.do_predict:\n",
            "                print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
            "                exp.predict(setting, True)\n",
            "\n",
            "            torch.cuda.empty_cache()\n",
            "    else:\n",
            "        ii = 0\n",
            "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n",
            "                                                                                                    args.model,\n",
            "                                                                                                    args.data,\n",
            "                                                                                                    args.features,\n",
            "                                                                                                    args.seq_len,\n",
            "                                                                                                    args.label_len,\n",
            "                                                                                                    args.pred_len,\n",
            "                                                                                                    args.d_model,\n",
            "                                                                                                    args.n_heads,\n",
            "                                                                                                    args.e_layers,\n",
            "                                                                                                    args.d_layers,\n",
            "                                                                                                    args.d_ff,\n",
            "                                                                                                    args.factor,\n",
            "                                                                                                    args.embed,\n",
            "                                                                                                    args.distil,\n",
            "                                                                                                    args.des, ii)\n",
            "\n",
            "        exp = Exp(args)  # set experiments\n",
            "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -R \"unfold(\" -n PatchTST_supervised | head -n 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7GQxRAXGWz6",
        "outputId": "caeacafa-5105-4be6-b19e-bcc5130245c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PatchTST_supervised/layers/PatchTST_backbone.py:78:        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -R \"PatchTST_backbone\" -n PatchTST_supervised | head -n 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsxXkN2uGdy3",
        "outputId": "7d7c1dfb-2323-45cc-87dc-217ba56b773e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PatchTST_supervised/models/PatchTST.py:11:from layers.PatchTST_backbone import PatchTST_backbone\n",
            "PatchTST_supervised/models/PatchTST.py:40:            encoder = PatchTST_backbone(\n",
            "PatchTST_supervised/models/PatchTST.py:194:                self.model_trend = PatchTST_backbone(c_in=c_in, context_window = context_window, target_window=target_window, patch_len=patch_len, stride=stride, \n",
            "PatchTST_supervised/models/PatchTST.py:202:                self.model_res = PatchTST_backbone(c_in=c_in, context_window = context_window, target_window=target_window, patch_len=patch_len, stride=stride, \n",
            "PatchTST_supervised/models/PatchTST.py:211:                self.model = PatchTST_backbone(c_in=c_in, context_window = context_window, target_window=target_window, patch_len=patch_len, stride=stride, \n",
            "PatchTST_supervised/layers/PatchTST_backbone.py:1:__all__ = ['PatchTST_backbone']\n",
            "PatchTST_supervised/layers/PatchTST_backbone.py:16:class PatchTST_backbone(nn.Module):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,120p' PatchTST_supervised/scripts/PatchTST/weather_multiscale_crosschannel.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s615Yn8IRtQ",
        "outputId": "c1eb4883-0d49-4db4-a426-0a3131d5abc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "\n",
            "# Multi-Scale + Cross-Channel PatchTST for Weather Forecasting\n",
            "# Combines both enhancements for maximum performance:\n",
            "#   - Multi-scale: Captures temporal patterns at 6hr, 12hr, 24hr scales\n",
            "#   - Cross-channel: Enables interaction between weather variables\n",
            "\n",
            "model_name=PatchTST\n",
            "random_seed=2021\n",
            "\n",
            "root_path_name=./dataset/\n",
            "data_path_name=weather.csv\n",
            "model_id_name=weather\n",
            "data_name=custom\n",
            "\n",
            "seq_len=336\n",
            "\n",
            "# Enable BOTH enhancements\n",
            "multi_scale=1\n",
            "channel_independent=0        # 0 = cross-channel (variables interact)\n",
            "\n",
            "# Multi-scale configuration\n",
            "patch_lengths=\"6,12,24\"      # Three temporal scales\n",
            "patch_strides=\"3,6,12\"       # 50% overlap for each\n",
            "patch_weights=\"0.2,0.5,0.3\"  # Balanced fusion\n",
            "\n",
            "for pred_len in 96 192 336 720\n",
            "do\n",
            "    python -u run_longExp.py \\\n",
            "      --random_seed $random_seed \\\n",
            "      --is_training 1 \\\n",
            "      --root_path $root_path_name \\\n",
            "      --data_path $data_path_name \\\n",
            "      --model_id $model_id_name'_multiCross_'$seq_len'_'$pred_len \\\n",
            "      --model $model_name \\\n",
            "      --data $data_name \\\n",
            "      --features M \\\n",
            "      --seq_len $seq_len \\\n",
            "      --pred_len $pred_len \\\n",
            "      --enc_in 21 \\\n",
            "      --channel_independent $channel_independent \\\n",
            "      --multi_scale $multi_scale \\\n",
            "      --patch_lengths $patch_lengths \\\n",
            "      --patch_strides $patch_strides \\\n",
            "      --patch_weights $patch_weights \\\n",
            "      --e_layers 3 \\\n",
            "      --n_heads 16 \\\n",
            "      --d_model 128 \\\n",
            "      --d_ff 256 \\\n",
            "      --dropout 0.2\\\n",
            "      --fc_dropout 0.2\\\n",
            "      --head_dropout 0\\\n",
            "      --patch_len 16\\\n",
            "      --stride 8\\\n",
            "      --des 'MultiScale_CrossChannel_Exp' \\\n",
            "      --train_epochs 100\\\n",
            "      --patience 20\\\n",
            "      --itr 1 --batch_size 128 --learning_rate 0.0001 >logs/LongForecasting/$model_name'_MultiCross_'$model_id_name'_'$seq_len'_'$pred_len.log \n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -R \"PatchTST_backbone\" -n PatchTST_supervised | head -n 30\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5ymYcInIsW4",
        "outputId": "8b5771ea-f6a5-41bd-cee1-2db714f51176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PatchTST_supervised/models/PatchTST.py:11:from layers.PatchTST_backbone import PatchTST_backbone\n",
            "PatchTST_supervised/models/PatchTST.py:40:            encoder = PatchTST_backbone(\n",
            "PatchTST_supervised/models/PatchTST.py:194:                self.model_trend = PatchTST_backbone(c_in=c_in, context_window = context_window, target_window=target_window, patch_len=patch_len, stride=stride, \n",
            "PatchTST_supervised/models/PatchTST.py:202:                self.model_res = PatchTST_backbone(c_in=c_in, context_window = context_window, target_window=target_window, patch_len=patch_len, stride=stride, \n",
            "PatchTST_supervised/models/PatchTST.py:211:                self.model = PatchTST_backbone(c_in=c_in, context_window = context_window, target_window=target_window, patch_len=patch_len, stride=stride, \n",
            "PatchTST_supervised/layers/PatchTST_backbone.py:1:__all__ = ['PatchTST_backbone']\n",
            "PatchTST_supervised/layers/PatchTST_backbone.py:16:class PatchTST_backbone(nn.Module):\n"
          ]
        }
      ]
    }
  ]
}