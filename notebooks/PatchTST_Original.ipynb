{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96aa7712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content/PatchTST\n"
     ]
    }
   ],
   "source": [
    "# Clone PatchTST repository and set it as working directory\n",
    "import os\n",
    "\n",
    "# Change to the repository directory\n",
    "os.chdir('/content/PatchTST')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808daab9",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation <a id='setup'></a>\n",
    "\n",
    "First, let's import necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b44421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.9.0+cu126\n",
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add PatchTST_supervised to path\n",
    "sys.path.append('/content/PatchTST/PatchTST_supervised')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baec37",
   "metadata": {},
   "source": [
    "## 2. Understanding the PatchTST Architecture <a id='architecture'></a>\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "**Patching**: Time series is segmented into subseries-level patches which serve as input tokens to the Transformer.\n",
    "\n",
    "**Channel-independence**: Each channel contains a single univariate time series that shares the same embedding and Transformer weights across all series.\n",
    "\n",
    "### Architecture Components:\n",
    "1. **RevIN (Reversible Instance Normalization)**: Normalizes input data\n",
    "2. **Patching Layer**: Segments time series into patches\n",
    "3. **Transformer Encoder**: Processes patches\n",
    "4. **Prediction Head**: Maps encoded patches to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf011a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to: /content/PatchTST/PatchTST_supervised\n",
      "Back to: /content/PatchTST\n",
      "\n",
      "==================================================\n",
      "PatchTST Architecture Overview\n",
      "==================================================\n",
      "\n",
      "1. Input Time Series: [Batch, Seq_len, Channels]\n",
      "   ↓\n",
      "2. RevIN: Normalization\n",
      "   ↓\n",
      "3. Patching: Divide into patches [Batch, Channels, Patch_num, Patch_len]\n",
      "   ↓\n",
      "4. Transformer Encoder: Process patches\n",
      "   ↓\n",
      "5. Flatten & Linear Head: Generate predictions\n",
      "   ↓\n",
      "6. RevIN Denormalization\n",
      "   ↓\n",
      "7. Output: [Batch, Pred_len, Channels]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Change to PatchTST_supervised directory for imports\n",
    "os.chdir('/content/PatchTST/PatchTST_supervised')\n",
    "dataset_path='/content/PatchTST/datasets/weather'\n",
    "model_checkopoints='/content/model/checkpoints_weather'\n",
    "print(f\"Changed to: {os.getcwd()}\")\n",
    "\n",
    "# Import PatchTST components\n",
    "from models.PatchTST import Model as PatchTST\n",
    "from layers.PatchTST_backbone import PatchTST_backbone\n",
    "from layers.PatchTST_layers import *\n",
    "\n",
    "# Change back to root directory\n",
    "os.chdir('..')\n",
    "print(f\"Back to: {os.getcwd()}\")\n",
    "\n",
    "# Visualize the architecture\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PatchTST Architecture Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n1. Input Time Series: [Batch, Seq_len, Channels]\")\n",
    "print(\"   ↓\")\n",
    "print(\"2. RevIN: Normalization\")\n",
    "print(\"   ↓\")\n",
    "print(\"3. Patching: Divide into patches [Batch, Channels, Patch_num, Patch_len]\")\n",
    "print(\"   ↓\")\n",
    "print(\"4. Transformer Encoder: Process patches\")\n",
    "print(\"   ↓\")\n",
    "print(\"5. Flatten & Linear Head: Generate predictions\")\n",
    "print(\"   ↓\")\n",
    "print(\"6. RevIN Denormalization\")\n",
    "print(\"   ↓\")\n",
    "print(\"7. Output: [Batch, Pred_len, Channels]\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b28ce",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preparation <a id='data'></a>\n",
    "\n",
    "Let's explore the data loading process and prepare a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd65c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 2021\n"
     ]
    }
   ],
   "source": [
    "from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom\n",
    "from data_provider.data_factory import data_provider\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "# Define a simple configuration class\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 2021  # Original PatchTST default seed\n",
    "\n",
    "        # Data parameters\n",
    "        self.data = 'custom'  # Use 'custom' for weather dataset\n",
    "        self.root_path = dataset_path\n",
    "        self.data_path = 'weather.csv'\n",
    "        self.features = 'M'  # M: multivariate, S: univariate, MS: multivariate to univariate\n",
    "        self.target = 'OT'\n",
    "        self.freq = '10min'  # 10 min intervals for weather data\n",
    "        self.embed = 'timeF'\n",
    "        \n",
    "        # Forecasting task\n",
    "        self.seq_len = 336  # Input sequence length (look back window)\n",
    "        self.label_len = 48  # Decoder start token (not used in PatchTST)\n",
    "        self.pred_len = 336  # Prediction length (prediction window)\n",
    "        \n",
    "        # Model parameters\n",
    "        self.model = 'PatchTST'\n",
    "        self.enc_in = 21  # Number of input channels (weather has 21 features)\n",
    "        self.dec_in = 21\n",
    "        self.c_out = 21  # Number of output channels\n",
    "        self.d_model = 128  # Dimension of model\n",
    "        self.n_heads = 8  # Number of attention heads\n",
    "        self.e_layers = 3  # Number of encoder layers\n",
    "        self.d_layers = 1  # Decoder layers (not used in PatchTST)\n",
    "        self.d_ff = 256  # Dimension of fcn\n",
    "        self.dropout = 0.2\n",
    "        self.fc_dropout = 0.2\n",
    "        self.head_dropout = 0.0\n",
    "        \n",
    "        # PatchTST specific\n",
    "        self.patch_len = 16  # Length of each patch\n",
    "        self.stride = 8  # Stride for patching\n",
    "        self.padding_patch = 'end'\n",
    "        self.revin = 1  # Use RevIN\n",
    "        self.affine = 0\n",
    "        self.subtract_last = 0\n",
    "        self.decomposition = 0\n",
    "        self.kernel_size = 25\n",
    "        self.individual = 0  # Individual head for each channel\n",
    "        \n",
    "        # Training parameters\n",
    "        self.batch_size = 16      # Original PatchTST batch size\n",
    "        self.learning_rate = 0.0001  # Standard learning rate\n",
    "        self.train_epochs = 100   # Max epochs (early stopping will kick in)\n",
    "        self.patience = 3        # Early stopping patience\n",
    "        self.num_workers = 0      # No multiprocessing (Colab compatible)\n",
    "        self.lradj = 'type3'      # Learning rate adjustment type\n",
    "        self.use_amp = False      # No automatic mixed precision\n",
    "        self.pct_start = 0.3      # OneCycleLR warmup percentage\n",
    "        \n",
    "        # GPU\n",
    "        self.use_gpu = True if torch.cuda.is_available() else False\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0'\n",
    "\n",
    "        # Other\n",
    "        self.checkpoints = model_checkopoints\n",
    "        self.output_attention = False  # Don't output attention weights\n",
    "        self.embed_type = 0       # Default embedding type\n",
    "        self.activation = 'gelu'  # Activation function\n",
    "        self.distil = True        # Use distillation (for Informer, not PatchTST)\n",
    "        self.factor = 1           # Attention factor\n",
    "        self.moving_avg = 25      # Moving average window\n",
    "        self.do_predict = False   # Not in prediction mode\n",
    "        self.itr = 1              # Number of experiment iterations\n",
    "        self.des = 'Exp'          # Experiment description\n",
    "        self.loss = 'mse'         # Loss function\n",
    "        \n",
    "args = Config()\n",
    "set_seed(args.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed929de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 36040\n",
      "val 4935\n",
      "test 10204\n",
      "\n",
      "Data Loaders Created:\n",
      "  Training samples: 36040\n",
      "  Validation samples: 4935\n",
      "  Test samples: 10204\n",
      "\n",
      "Batch shapes:\n",
      "  Input (batch_x): torch.Size([16, 512, 21])\n",
      "  Target (batch_y): torch.Size([16, 384, 21])\n",
      "  Input time features (batch_x_mark): torch.Size([16, 512, 5])\n",
      "  Target time features (batch_y_mark): torch.Size([16, 384, 5])\n"
     ]
    }
   ],
   "source": [
    "train_data, train_loader = data_provider(args, flag='train')\n",
    "val_data, val_loader = data_provider(args, flag='val')\n",
    "test_data, test_loader = data_provider(args, flag='test')\n",
    "\n",
    "print(f\"\\nData Loaders Created:\")\n",
    "print(f\"  Training samples: {len(train_data)}\")\n",
    "print(f\"  Validation samples: {len(val_data)}\")\n",
    "print(f\"  Test samples: {len(test_data)}\")\n",
    "\n",
    "# Inspect a batch\n",
    "for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "    print(f\"\\nBatch shapes:\")\n",
    "    print(f\"  Input (batch_x): {batch_x.shape}\")\n",
    "    print(f\"  Target (batch_y): {batch_y.shape}\")\n",
    "    print(f\"  Input time features (batch_x_mark): {batch_x_mark.shape}\")\n",
    "    print(f\"  Target time features (batch_y_mark): {batch_y_mark.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f266e",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Creation <a id='model'></a>\n",
    "\n",
    "Let's create the PatchTST model and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191e5c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "Model created successfully!\n",
      "\n",
      "Model Architecture:\n",
      "Model(\n",
      "  (model): PatchTST_backbone(\n",
      "    (revin_layer): RevIN()\n",
      "    (padding_patch_layer): ReplicationPad1d((0, 8))\n",
      "    (backbone): TSTiEncoder(\n",
      "      (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (encoder): TSTEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-2): 3 x TSTEncoderLayer(\n",
      "            (self_attn): _MultiheadAttention(\n",
      "              (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (sdp_attn): _ScaledDotProductAttention(\n",
      "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (to_out): Sequential(\n",
      "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (1): Dropout(p=0.2, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (dropout_attn): Dropout(p=0.2, inplace=False)\n",
      "            (norm_attn): Sequential(\n",
      "              (0): Transpose()\n",
      "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): Transpose()\n",
      "            )\n",
      "            (ff): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "              (1): GELU(approximate='none')\n",
      "              (2): Dropout(p=0.2, inplace=False)\n",
      "              (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "            )\n",
      "            (dropout_ffn): Dropout(p=0.2, inplace=False)\n",
      "            (norm_ffn): Sequential(\n",
      "              (0): Transpose()\n",
      "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): Transpose()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (head): Flatten_Head(\n",
      "      (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "      (linear): Linear(in_features=8192, out_features=336, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = PatchTST(args).float()\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\nModel created successfully!\")\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e44c9",
   "metadata": {},
   "source": [
    "## 5. Training the Model <a id='training'></a>\n",
    "\n",
    "Now let's set up the training loop with proper optimization and learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44848d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy compatibility patch applied for np.Inf -> np.inf\n"
     ]
    }
   ],
   "source": [
    "# Fix NumPy 2.0 compatibility issue\n",
    "import numpy as np\n",
    "if not hasattr(np, 'Inf'):\n",
    "    np.Inf = np.inf\n",
    "    np.NaN = np.nan\n",
    "    np.NAN = np.nan\n",
    "    np.NINF = np.NINF if hasattr(np, 'NINF') else -np.inf\n",
    "    print(\"NumPy compatibility patch applied for np.Inf -> np.inf\")\n",
    "else:\n",
    "    print(\"NumPy already has np.Inf attribute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921424db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Setup:\n",
      "  Criterion: MSE Loss\n",
      "  Optimizer: Adam (lr=0.0001)\n",
      "  Scheduler: OneCycleLR\n",
      "  Training steps per epoch: 2252\n",
      "  Total epochs: 100\n"
     ]
    }
   ],
   "source": [
    "from utils.tools import EarlyStopping, adjust_learning_rate\n",
    "from utils.metrics import metric\n",
    "import time\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "# Learning rate scheduler\n",
    "if os.path.exists(dataset_path):\n",
    "    train_steps = len(train_loader)\n",
    "    scheduler = lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        steps_per_epoch=train_steps,\n",
    "        pct_start=args.pct_start,\n",
    "        epochs=args.train_epochs,\n",
    "        max_lr=args.learning_rate\n",
    "    )\n",
    "    \n",
    "    print(f\"Training Setup:\")\n",
    "    print(f\"  Criterion: MSE Loss\")\n",
    "    print(f\"  Optimizer: Adam (lr={args.learning_rate})\")\n",
    "    print(f\"  Scheduler: OneCycleLR\")\n",
    "    print(f\"  Training steps per epoch: {train_steps}\")\n",
    "    print(f\"  Total epochs: {args.train_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05413f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified evaluation function - only MSE and MAE\n",
    "def evaluate_model(model, test_loader, device, args):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    inputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in test_loader:\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_x)\n",
    "            \n",
    "            # Extract predictions\n",
    "            f_dim = -1 if args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -args.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -args.pred_len:, f_dim:]\n",
    "            \n",
    "            # Store results\n",
    "            preds.append(outputs.detach().cpu().numpy())\n",
    "            trues.append(batch_y.detach().cpu().numpy())\n",
    "            inputs.append(batch_x.detach().cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    inputs = np.concatenate(inputs, axis=0)\n",
    "    \n",
    "    # Calculate only MSE and MAE\n",
    "    mse = np.mean((preds - trues) ** 2)\n",
    "    mae = np.mean(np.abs(preds - trues))\n",
    "    \n",
    "    print(\"\\nTest Set Evaluation Metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"  MSE:  {mse:.7f}\")\n",
    "    print(f\"  MAE:  {mae:.7f}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return preds, trues, inputs, {'mse': mse, 'mae': mae}\n",
    "\n",
    "# Count model parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in val_loader:\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_x)\n",
    "            \n",
    "            # Calculate loss\n",
    "            f_dim = -1 if args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -args.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -args.pred_len:, f_dim:]\n",
    "            \n",
    "            loss = criterion(outputs.cpu(), batch_y.cpu())\n",
    "            total_loss.append(loss.item())\n",
    "    \n",
    "    model.train()\n",
    "    return np.mean(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9afb1b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Parameters:\n",
      "  Total parameters: 1,994,427\n",
      "  Trainable parameters: 1,994,424\n",
      "  Model size: ~7.61 MB (fp32)\n",
      "\n",
      "==========================================================================================\n",
      "STARTING MULTI-MODEL TRAINING WITH DIFFERENT CONFIGURATIONS\n",
      "==========================================================================================\n",
      "\n",
      "==========================================================================================\n",
      "Configuration 1/1: PatchTST/42 (pred_len=336, d_model=42)\n",
      "==========================================================================================\n",
      "  Updated config: pred_len=336, d_model=128, n_heads=16, d_ff=256\n",
      "  Loading data with pred_len=336...\n",
      "train 36040\n",
      "val 4935\n",
      "test 10204\n",
      "    Training samples: 36040\n",
      "    Validation samples: 4935\n",
      "    Test samples: 10204\n",
      "  Creating model...\n",
      "  Model parameters: 3,160,659 (trainable: 3,160,656)\n",
      "  Starting training (max 100 epochs)...\n",
      "    Epoch   1/100 | Time: 163.53s | Train Loss: 1.0070179 | Val Loss: 0.8861486\n",
      "Updating learning rate to 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-136223470.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train multiple model configurations with different prediction lengths\n",
    "# This cell handles TRAINING ONLY and saves checkpoints\n",
    "\n",
    "import datetime\n",
    "\n",
    "total, trainable = count_parameters(model)\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"  Total parameters: {total:,}\")\n",
    "print(f\"  Trainable parameters: {trainable:,}\")\n",
    "print(f\"  Model size: ~{total * 4 / 1024 / 1024:.2f} MB (fp32)\")\n",
    "\n",
    "# Training configurations: (pred_len, d_model, model_name)\n",
    "training_configs = [\n",
    "    # (336, 64, 'PatchTST/64'),\n",
    "    (336, 42, 'PatchTST/42'),\n",
    "    # (720, 64, 'PatchTST/64'),\n",
    "    # (720, 42, 'PatchTST/42'),\n",
    "]\n",
    "\n",
    "# Dictionary to store checkpoint paths\n",
    "checkpoint_registry = {\n",
    "    336: {\n",
    "        # 'PatchTST/64': None,\n",
    "        'PatchTST/42': None\n",
    "    },\n",
    "    # 720: {'PatchTST/64': None, 'PatchTST/42': None}\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"STARTING MULTI-MODEL TRAINING WITH DIFFERENT CONFIGURATIONS\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for config_idx, (pred_len, d_model, model_name) in enumerate(training_configs, 1):\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"Configuration {config_idx}/{len(training_configs)}: {model_name} (pred_len={pred_len}, d_model={d_model})\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    # Update configuration\n",
    "    args.pred_len = pred_len\n",
    "    args.d_model = d_model\n",
    "\n",
    "    # Adjust related parameters based on d_model\n",
    "    # For d_model=42: comes from patching (336-16)/8 + 1 = 42 patches\n",
    "    if d_model == 42:\n",
    "        args.n_heads = 3  # Divisor of 42\n",
    "        args.d_ff = 128\n",
    "    elif d_model == 64:\n",
    "        args.n_heads = 4\n",
    "        args.d_ff = 256\n",
    "    else:\n",
    "        args.n_heads = 8\n",
    "        args.d_ff = 256\n",
    "    \n",
    "    print(f\"  Updated config: pred_len={args.pred_len}, d_model={args.d_model}, n_heads={args.n_heads}, d_ff={args.d_ff}\")\n",
    "    print(f\"  Patching: seq_len={args.seq_len}, patch_len={args.patch_len}, stride={args.stride}\")\n",
    "    print(f\"  Number of patches: ({args.seq_len} - {args.patch_len})/{args.stride} + 1 = {(args.seq_len - args.patch_len) // args.stride + 1}\")\n",
    "    \n",
    "    # Recreate data loaders for new pred_len\n",
    "    print(f\"  Loading data with pred_len={args.pred_len}...\")\n",
    "    train_data, train_loader = data_provider(args, flag='train')\n",
    "    val_data, val_loader = data_provider(args, flag='val')\n",
    "    test_data, test_loader = data_provider(args, flag='test')\n",
    "    \n",
    "    print(f\"    Training samples: {len(train_data)}\")\n",
    "    print(f\"    Validation samples: {len(val_data)}\")\n",
    "    print(f\"    Test samples: {len(test_data)}\")\n",
    "    \n",
    "    # Create new model\n",
    "    print(f\"  Creating model...\")\n",
    "    model = PatchTST(args).float()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "    print(f\"  Model parameters: {total_params:,} (trainable: {trainable_params:,})\")\n",
    "    \n",
    "    # Setup training\n",
    "    train_steps = len(train_loader)\n",
    "    scheduler = lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        steps_per_epoch=train_steps,\n",
    "        pct_start=args.pct_start,\n",
    "        epochs=args.train_epochs,\n",
    "        max_lr=args.learning_rate\n",
    "    )\n",
    "    \n",
    "    # Reset training history\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=args.patience, verbose=False)\n",
    "    \n",
    "    # Training loop\n",
    "    setting = f\"{args.model}_{args.data}_sl{args.seq_len}_pl{args.pred_len}_dm{args.d_model}_patch{args.patch_len}\"\n",
    "    checkpoint_path = os.path.join(args.checkpoints, setting)\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"  Starting training (max {args.train_epochs} epochs)...\")\n",
    "    for epoch in range(args.train_epochs):\n",
    "        model.train()\n",
    "        epoch_time = time.time()\n",
    "        train_loss = []\n",
    "        \n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            \n",
    "            f_dim = -1 if args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -args.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -args.pred_len:, f_dim:]\n",
    "            \n",
    "            loss = criterion(outputs, batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if args.lradj == 'TST':\n",
    "                adjust_learning_rate(optimizer, scheduler, epoch + 1, args, printout=False)\n",
    "                scheduler.step()\n",
    "        \n",
    "        # Validation and testing\n",
    "        train_loss_avg = np.mean(train_loss)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        test_loss = validate(model, test_loader, criterion, device)\n",
    "        \n",
    "        train_losses.append(train_loss_avg)\n",
    "        val_losses.append(val_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            epoch_duration = time.time() - epoch_time\n",
    "            print(f\"    Epoch {epoch+1:3d}/{args.train_epochs} | Time: {epoch_duration:.2f}s | \"\n",
    "                    f\"Train Loss: {train_loss_avg:.7f} | Val Loss: {val_loss:.7f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping(val_loss, model, checkpoint_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        if args.lradj != 'TST':\n",
    "            adjust_learning_rate(optimizer, scheduler, epoch + 1, args)\n",
    "    \n",
    "    # Save final checkpoint for this configuration\n",
    "    final_checkpoint_path = os.path.join(checkpoint_path, 'final_checkpoint.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_losses[-1] if train_losses else 0,\n",
    "        'val_loss': val_losses[-1] if val_losses else 0,\n",
    "        'config': vars(args)\n",
    "    }, final_checkpoint_path)\n",
    "    print(f\"  Final checkpoint saved to: {final_checkpoint_path}\")\n",
    "    \n",
    "    # Store checkpoint path in registry\n",
    "    checkpoint_registry[pred_len][model_name] = checkpoint_path\n",
    "\n",
    "\n",
    "print(\"Run the next cell to generate evaluation metrics and visualizations\")\n",
    "\n",
    "print(\"Checkpoint locations saved in 'checkpoint_registry' variable\")print(f\"{'='*90}\\n\")\n",
    "\n",
    "checkpoint_registry[pred_len][model_name] = checkpoint_path\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f944bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "LOADING CHECKPOINTS AND EVALUATING MODELS\n",
      "==========================================================================================\n",
      "\n",
      "==========================================================================================\n",
      "Configuration 1/4: PatchTST/64 (pred_len=336, d_model=64)\n",
      "==========================================================================================\n",
      "  Loading data with pred_len=336...\n",
      "train 36040\n",
      "val 4935\n",
      "test 10204\n",
      "  Creating model for evaluation...\n",
      "  Loading best model from: /content/model/checkpoints_weather/PatchTST_custom_sl512_pl336_dm64_patch16/checkpoint.pth\n",
      "  Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation Metrics:\n",
      "==================================================\n",
      "  MSE:  0.3707829\n",
      "  MAE:  0.3848366\n",
      "==================================================\n",
      "\n",
      "==========================================================================================\n",
      "Configuration 2/4: PatchTST/42 (pred_len=336, d_model=42)\n",
      "==========================================================================================\n",
      "  Loading data with pred_len=336...\n",
      "train 36040\n",
      "val 4935\n",
      "test 10204\n",
      "  Creating model for evaluation...\n",
      "  Loading best model from: /content/model/checkpoints_weather/PatchTST_custom_sl512_pl336_dm42_patch16/checkpoint.pth\n",
      "  Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation Metrics:\n",
      "==================================================\n",
      "  MSE:  0.3694819\n",
      "  MAE:  0.3843580\n",
      "==================================================\n",
      "\n",
      "==========================================================================================\n",
      "Configuration 3/4: PatchTST/64 (pred_len=720, d_model=64)\n",
      "==========================================================================================\n",
      "  Loading data with pred_len=720...\n",
      "train 35656\n",
      "val 4551\n",
      "test 9820\n",
      "  Creating model for evaluation...\n",
      "  Loading best model from: /content/model/checkpoints_weather/PatchTST_custom_sl512_pl720_dm64_patch16/checkpoint.pth\n",
      "  Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation Metrics:\n",
      "==================================================\n",
      "  MSE:  0.4134089\n",
      "  MAE:  0.4122844\n",
      "==================================================\n",
      "\n",
      "==========================================================================================\n",
      "Configuration 4/4: PatchTST/42 (pred_len=720, d_model=42)\n",
      "==========================================================================================\n",
      "  Loading data with pred_len=720...\n",
      "train 35656\n",
      "val 4551\n",
      "test 9820\n",
      "  Creating model for evaluation...\n",
      "  Loading best model from: /content/model/checkpoints_weather/PatchTST_custom_sl512_pl720_dm42_patch16/checkpoint.pth\n",
      "  Evaluating model on test set...\n",
      "\n",
      "Test Set Evaluation Metrics:\n",
      "==================================================\n",
      "  MSE:  0.4105059\n",
      "  MAE:  0.4105389\n",
      "==================================================\n",
      "\n",
      "==========================================================================================\n",
      "EVALUATION COMPLETED\n",
      "==========================================================================================\n",
      "\n",
      "Results summary saved to: /content/model/checkpoints_weather/training_results_summary.txt\n",
      "\n",
      "==========================================================================================\n",
      "FINAL RESULTS COMPARISON\n",
      "==========================================================================================\n",
      "\n",
      "Pred Length     PatchTST/64 MSE    PatchTST/64 MAE    PatchTST/42 MSE    PatchTST/42 MAE   \n",
      "------------------------------------------------------------------------------------------\n",
      "336             0.3707829          0.3848366          0.3694819          0.3843580         \n",
      "720             0.4134089          0.4122844          0.4105059          0.4105389         \n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load saved checkpoints and generate evaluation metrics and visualizations\n",
    "# This cell handles EVALUATION and VISUALIZATION ONLY\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Dictionary to store all results\n",
    "all_results = {\n",
    "    336: {\n",
    "        'PatchTST/64': {'mse': None, 'mae': None, 'checkpoint_path': None},\n",
    "        'PatchTST/42': {'mse': None, 'mae': None, 'checkpoint_path': None}\n",
    "    },\n",
    "    720: {\n",
    "        'PatchTST/64': {'mse': None, 'mae': None, 'checkpoint_path': None},\n",
    "        'PatchTST/42': {'mse': None, 'mae': None, 'checkpoint_path': None}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Training configurations: (pred_len, d_model, model_name)\n",
    "training_configs = [\n",
    "    # (336, 64, 'PatchTST/64'),\n",
    "    (336, 42, 'PatchTST/42'),\n",
    "    # (720, 64, 'PatchTST/64'),\n",
    "    # (720, 42, 'PatchTST/42'),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"LOADING CHECKPOINTS AND EVALUATING MODELS\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for config_idx, (pred_len, d_model, model_name) in enumerate(training_configs, 1):\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"Configuration {config_idx}/{len(training_configs)}: {model_name} (pred_len={pred_len}, d_model={d_model})\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    # Update configuration\n",
    "    args.pred_len = pred_len\n",
    "    args.d_model = d_model\n",
    "    \n",
    "    # Adjust related parameters proportionally (MUST MATCH TRAINING)\n",
    "    if d_model == 42:\n",
    "        args.n_heads = 3  # Adjust heads for smaller model\n",
    "        args.d_ff = 128\n",
    "    elif d_model == 64:\n",
    "        args.n_heads = 4\n",
    "        args.d_ff = 256\n",
    "    else:\n",
    "        args.n_heads = 8  # Original PatchTST\n",
    "        args.d_ff = 256\n",
    "    \n",
    "    # Recreate data loaders for evaluation\n",
    "    print(f\"  Loading data with pred_len={args.pred_len}...\")\n",
    "    train_data, train_loader = data_provider(args, flag='train')\n",
    "    val_data, val_loader = data_provider(args, flag='val')\n",
    "    test_data, test_loader = data_provider(args, flag='test')\n",
    "    \n",
    "    # Create model for loading checkpoint\n",
    "    print(f\"  Creating model for evaluation...\")\n",
    "    model = PatchTST(args).float()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Get checkpoint path\n",
    "    checkpoint_path = checkpoint_registry[pred_len][model_name]\n",
    "    best_model_path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
    "    final_checkpoint_path = os.path.join(checkpoint_path, 'final_checkpoint.pth')\n",
    "    \n",
    "    # Load best model from checkpoint\n",
    "    print(f\"  Loading best model from: {best_model_path}\")\n",
    "    model.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(f\"  Evaluating model on test set...\")\n",
    "    preds, trues, inputs, metrics = evaluate_model(model, test_loader, device, args)\n",
    "    \n",
    "    # Store results\n",
    "    all_results[pred_len][model_name]['mse'] = metrics['mse']\n",
    "    all_results[pred_len][model_name]['mae'] = metrics['mae']\n",
    "    all_results[pred_len][model_name]['checkpoint_path'] = final_checkpoint_path\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"EVALUATION COMPLETED\")\n",
    "print(f\"{'='*90}\\n\")\n",
    "\n",
    "# Save all results to a file\n",
    "results_log_path = os.path.join(args.checkpoints, 'training_results_summary.txt')\n",
    "with open(results_log_path, 'w') as f:\n",
    "    f.write(\"PatchTST Multi-Configuration Training Results\\n\")\n",
    "    f.write(f\"Timestamp: {datetime.datetime.now()}\\n\")\n",
    "    f.write(\"=\"*90 + \"\\n\\n\")\n",
    "    \n",
    "    for pred_len in [336, 720]:\n",
    "        f.write(f\"Prediction Length: {pred_len}\\n\")\n",
    "        f.write(\"-\"*90 + \"\\n\")\n",
    "        for model_name in ['PatchTST/64', 'PatchTST/42']:\n",
    "            mse = all_results[pred_len][model_name]['mse']\n",
    "            mae = all_results[pred_len][model_name]['mae']\n",
    "            checkpoint = all_results[pred_len][model_name]['checkpoint_path']\n",
    "            f.write(f\"  {model_name}:\\n\")\n",
    "            f.write(f\"    MSE: {mse:.7f}\\n\")\n",
    "            f.write(f\"    MAE: {mae:.7f}\\n\")\n",
    "            f.write(f\"    Checkpoint: {checkpoint}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Results summary saved to: {results_log_path}\")\n",
    "\n",
    "# Display final comparison table\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "print(f\"\\n{'Pred Length':<15} {'PatchTST/64 MSE':<18} {'PatchTST/64 MAE':<18} {'PatchTST/42 MSE':<18} {'PatchTST/42 MAE':<18}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for pred_len in [336, 720]:\n",
    "    mse_64 = all_results[pred_len]['PatchTST/64']['mse']\n",
    "    mae_64 = all_results[pred_len]['PatchTST/64']['mae']\n",
    "    mse_42 = all_results[pred_len]['PatchTST/42']['mse']\n",
    "    mae_42 = all_results[pred_len]['PatchTST/42']['mae']\n",
    "    \n",
    "    mse_64_str = f\"{mse_64:.7f}\" if mse_64 is not None else \"N/A\"\n",
    "    mae_64_str = f\"{mae_64:.7f}\" if mae_64 is not None else \"N/A\"\n",
    "    mse_42_str = f\"{mse_42:.7f}\" if mse_42 is not None else \"N/A\"\n",
    "    mae_42_str = f\"{mae_42:.7f}\" if mae_42 is not None else \"N/A\"\n",
    "    \n",
    "    print(f\"{str(pred_len):<15} {mse_64_str:<18} {mae_64_str:<18} {mse_42_str:<18} {mae_42_str:<18}\")\n",
    "\n",
    "print(\"=\"*90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
